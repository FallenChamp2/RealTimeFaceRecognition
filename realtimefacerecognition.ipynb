{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-01-08T08:06:37.179396Z","iopub.execute_input":"2022-01-08T08:06:37.179660Z","iopub.status.idle":"2022-01-08T08:06:37.185325Z","shell.execute_reply.started":"2022-01-08T08:06:37.179632Z","shell.execute_reply":"2022-01-08T08:06:37.184629Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import os\nfrom os import listdir","metadata":{"execution":{"iopub.status.busy":"2022-01-08T08:06:37.187032Z","iopub.execute_input":"2022-01-08T08:06:37.187854Z","iopub.status.idle":"2022-01-08T08:06:37.195144Z","shell.execute_reply.started":"2022-01-08T08:06:37.187816Z","shell.execute_reply":"2022-01-08T08:06:37.194446Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *","metadata":{"execution":{"iopub.status.busy":"2022-01-08T08:06:37.196444Z","iopub.execute_input":"2022-01-08T08:06:37.196831Z","iopub.status.idle":"2022-01-08T08:06:37.203340Z","shell.execute_reply.started":"2022-01-08T08:06:37.196795Z","shell.execute_reply":"2022-01-08T08:06:37.202650Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image_dataset_from_directory, image\n\ntrain_directory = r'../input/face-mask-12k-images-dataset/Face Mask Dataset/Train'\nvalid_directory = r'../input/face-mask-12k-images-dataset/Face Mask Dataset/Validation'\n\ntrain_dataset = image_dataset_from_directory(train_directory,\n                                            seed = 2059,\n                                            image_size = (160, 160),\n                                            batch_size = 16)\n\n\nvalid_dataset = image_dataset_from_directory(valid_directory,\n                                            seed = 2059,\n                                            image_size = (160, 160),\n                                            batch_size = 16)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T08:06:37.204833Z","iopub.execute_input":"2022-01-08T08:06:37.205092Z","iopub.status.idle":"2022-01-08T08:06:38.728227Z","shell.execute_reply.started":"2022-01-08T08:06:37.205061Z","shell.execute_reply":"2022-01-08T08:06:38.727574Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Found 10000 files belonging to 2 classes.\nFound 800 files belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"labels = train_dataset.class_names\nprint(len(labels))","metadata":{"execution":{"iopub.status.busy":"2022-01-08T08:06:38.730223Z","iopub.execute_input":"2022-01-08T08:06:38.730543Z","iopub.status.idle":"2022-01-08T08:06:38.735575Z","shell.execute_reply.started":"2022-01-08T08:06:38.730506Z","shell.execute_reply":"2022-01-08T08:06:38.734511Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"2\n","output_type":"stream"}]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size = (3, 3), input_shape = (160, 160, 3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(256, kernel_size = (3, 3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(512, kernel_size = (3, 3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size = (2, 2), padding = 'same'))\nmodel.add(BatchNormalization())\n\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation = 'relu'))\n\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(len(labels), activation = 'softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-01-08T08:06:38.737265Z","iopub.execute_input":"2022-01-08T08:06:38.737591Z","iopub.status.idle":"2022-01-08T08:06:38.891041Z","shell.execute_reply.started":"2022-01-08T08:06:38.737544Z","shell.execute_reply":"2022-01-08T08:06:38.890226Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\n\n# ModelCheckpoint to save model in case of \n# interrupting the learning process\ncheckpoint = ModelCheckpoint(\"./face_mask_classifierCC.h5\",\n                             monitor = \"val_loss\",\n                             mode = \"min\",\n                             save_best_only = True,\n                             verbose = 1)\n\n# EarlyStopping to find best model with a large number of epochs\nearlystop = EarlyStopping(monitor = 'val_loss',\n                          restore_best_weights = True,\n                          patience = 3,  # number of epochs with \n                                       # no improvement after which \n                                       # training will be stopped\n                          verbose=1)\n\ncallbacks = [earlystop, checkpoint]\nmodel.compile(loss = 'sparse_categorical_crossentropy',\n                        optimizer = Adam(learning_rate = 0.01),\n                        metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-01-08T08:06:38.893296Z","iopub.execute_input":"2022-01-08T08:06:38.893884Z","iopub.status.idle":"2022-01-08T08:06:38.906541Z","shell.execute_reply.started":"2022-01-08T08:06:38.893842Z","shell.execute_reply":"2022-01-08T08:06:38.905771Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"epochs = 20\n\nhistory = model.fit(\n    train_dataset,\n    epochs = epochs,\n    callbacks = callbacks,\n    validation_data = valid_dataset)\n\nmodel.save(\"./face_mask_classifierCC.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-01-08T08:06:38.908086Z","iopub.execute_input":"2022-01-08T08:06:38.908418Z","iopub.status.idle":"2022-01-08T08:10:32.142605Z","shell.execute_reply.started":"2022-01-08T08:06:38.908377Z","shell.execute_reply":"2022-01-08T08:10:32.141907Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Epoch 1/20\n625/625 [==============================] - 18s 28ms/step - loss: 0.4173 - accuracy: 0.8909 - val_loss: 0.1991 - val_accuracy: 0.9375\n\nEpoch 00001: val_loss improved from inf to 0.19906, saving model to ./face_mask_classifierCC.h5\nEpoch 2/20\n625/625 [==============================] - 18s 28ms/step - loss: 0.1928 - accuracy: 0.9344 - val_loss: 2.5276 - val_accuracy: 0.7188\n\nEpoch 00002: val_loss did not improve from 0.19906\nEpoch 3/20\n625/625 [==============================] - 17s 26ms/step - loss: 0.1305 - accuracy: 0.9609 - val_loss: 0.1371 - val_accuracy: 0.9525\n\nEpoch 00003: val_loss improved from 0.19906 to 0.13709, saving model to ./face_mask_classifierCC.h5\nEpoch 4/20\n625/625 [==============================] - 17s 27ms/step - loss: 0.1066 - accuracy: 0.9639 - val_loss: 0.0411 - val_accuracy: 0.9850\n\nEpoch 00004: val_loss improved from 0.13709 to 0.04109, saving model to ./face_mask_classifierCC.h5\nEpoch 5/20\n625/625 [==============================] - 17s 27ms/step - loss: 0.0761 - accuracy: 0.9737 - val_loss: 0.0387 - val_accuracy: 0.9887\n\nEpoch 00005: val_loss improved from 0.04109 to 0.03872, saving model to ./face_mask_classifierCC.h5\nEpoch 6/20\n625/625 [==============================] - 17s 28ms/step - loss: 0.0597 - accuracy: 0.9813 - val_loss: 0.0988 - val_accuracy: 0.9650\n\nEpoch 00006: val_loss did not improve from 0.03872\nEpoch 7/20\n625/625 [==============================] - 17s 27ms/step - loss: 0.0469 - accuracy: 0.9847 - val_loss: 0.0198 - val_accuracy: 0.9937\n\nEpoch 00007: val_loss improved from 0.03872 to 0.01983, saving model to ./face_mask_classifierCC.h5\nEpoch 8/20\n625/625 [==============================] - 17s 27ms/step - loss: 0.0556 - accuracy: 0.9823 - val_loss: 0.0424 - val_accuracy: 0.9862\n\nEpoch 00008: val_loss did not improve from 0.01983\nEpoch 9/20\n625/625 [==============================] - 17s 28ms/step - loss: 0.0524 - accuracy: 0.9832 - val_loss: 0.0161 - val_accuracy: 0.9937\n\nEpoch 00009: val_loss improved from 0.01983 to 0.01607, saving model to ./face_mask_classifierCC.h5\nEpoch 10/20\n625/625 [==============================] - 17s 27ms/step - loss: 0.0683 - accuracy: 0.9784 - val_loss: 0.0248 - val_accuracy: 0.9912\n\nEpoch 00010: val_loss did not improve from 0.01607\nEpoch 11/20\n625/625 [==============================] - 17s 27ms/step - loss: 0.0443 - accuracy: 0.9852 - val_loss: 0.0929 - val_accuracy: 0.9900\n\nEpoch 00011: val_loss did not improve from 0.01607\nEpoch 12/20\n625/625 [==============================] - 17s 27ms/step - loss: 0.0375 - accuracy: 0.9886 - val_loss: 9.8621 - val_accuracy: 0.9737\nRestoring model weights from the end of the best epoch.\n\nEpoch 00012: val_loss did not improve from 0.01607\nEpoch 00012: early stopping\n","output_type":"stream"}]}]}